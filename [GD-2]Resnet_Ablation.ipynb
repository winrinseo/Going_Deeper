{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[GD-2] Resnet_Ablation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트 : ResNet Ablation Study\n",
        "shortcut connection을 이용해 더 깊은 모델에서도 안정적으로 학습이 가능합니다.\n",
        "\n",
        "shortcut이 없는 모델과 비교해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "HQ47j4XhuHiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input,BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add, AveragePooling2D,Flatten\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "WrpL-R-e40YI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 ~ 1(또는 -1 ~ 1) 사이의 실수값으로 정규화한다.\n",
        "def normalize_and_resize_img(image, label):\n",
        "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "    image = tf.image.resize(image, [32, 32])\n",
        "    return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "#  전체 데이터셋을 모두 정규화한다.\n",
        "def apply_normalize_on_dataset(ds, is_test=False, batch_size=8):\n",
        "    ds = ds.map(\n",
        "        normalize_and_resize_img, \n",
        "        num_parallel_calls=1\n",
        "    )\n",
        "    ds = ds.batch(batch_size)\n",
        "    if not is_test:\n",
        "        ds = ds.repeat()\n",
        "        ds = ds.shuffle(200)\n",
        "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "l1mclBiZfE8f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCH = 100\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    shuffle_files=True,\n",
        "    with_info=True,\n",
        ")\n",
        "print(len(ds_train))\n",
        "print(len(ds_test))\n",
        "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
        "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi4ORSOoeS-e",
        "outputId": "7e131cc8-5b88-4b9f-e87a-ce0258452870"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet 34의 블록을 생성하는 함수를 정의합니다.\n",
        "이전 레이어에서 처음 데이터를 받았다면 크기가 절반이 되어있어 숏컷과 Add연산이 불가능합니다.\n",
        "\n",
        "따라서 이전 레이어로부터 처음 받은 블록에서는 숏컷의 크기를 조절할 필요가 있습니다."
      ],
      "metadata": {
        "id": "iEpkf-I7uGAx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ToaLVOdSeaTT"
      },
      "outputs": [],
      "source": [
        "#ResNet 34의 블록 생성 함수\n",
        "def basic_block(input,channel,i,stride=1):\n",
        "    x = input\n",
        "    shortcut = input\n",
        "    st = stride if i==0 else 1\n",
        "    output = Conv2D(filters=channel,kernel_size=(3,3),strides=st,padding='same')(x)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    output = Conv2D(filters=channel,kernel_size=(3,3),strides=1,padding='same')(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "    # 이전 레이어로부터 처음 받았다면 크기조절 필요\n",
        "    if st != 1:\n",
        "        shortcut = Conv2D(filters=channel,kernel_size=(1,1),strides=2,padding='same')(shortcut)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    output = Add()([output,shortcut])\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet34(num_classes = 10):\n",
        "    input_layer = Input(shape=(32, 32, 3))\n",
        "    output = Conv2D(filters=64,kernel_size=(3,3),strides=2,padding='same')(input_layer)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = MaxPooling2D(pool_size=(3,3),strides=2,padding='same')(output)\n",
        "    filter = [64,128,256,512]\n",
        "    num = [3,4,6,3]\n",
        "    s = 1\n",
        "    for n,f in zip(num,filter):\n",
        "        for i in range(n):\n",
        "            output = basic_block(output,f,i,s)\n",
        "        s+=1\n",
        "        if s>=2 : s=2\n",
        "    \n",
        "    \n",
        "    output = AveragePooling2D(pool_size=(1,1))(output)\n",
        "    output = Flatten(name='flatten')(output)\n",
        "    output = Dense(num_classes, activation='softmax', name='predictions')(output)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=input_layer, \n",
        "        outputs=output\n",
        "    )\n",
        "    \n",
        "    return model "
      ],
      "metadata": {
        "id": "30V9i15eiKRI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet34 = ResNet34()\n",
        "resnet34.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oWc9n3O_30I",
        "outputId": "984e18e3-fd55-4a7d-9842-35b32fadec13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 64)   1792        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 64)  256         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 8, 8, 64)     0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 8, 8, 64)     36928       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 8, 8, 64)     36928       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 8, 8, 64)    256         ['max_pooling2d[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 8, 8, 64)     0           ['activation_1[0][0]',           \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 8, 8, 64)     36928       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 8, 8, 64)     36928       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 64)    256         ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 8, 8, 64)     0           ['activation_3[0][0]',           \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 8, 8, 64)     36928       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 8, 8, 64)     36928       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 8, 8, 64)     0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 8, 8, 64)    256         ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 8, 8, 64)     0           ['activation_5[0][0]',           \n",
            "                                                                  'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 4, 4, 128)    73856       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 4, 4, 128)   512         ['conv2d_7[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 4, 4, 128)    147584      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 128)   512         ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 4, 4, 128)    8320        ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 4, 4, 128)   512         ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 4, 4, 128)    0           ['activation_7[0][0]',           \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 4, 4, 128)    147584      ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 4, 4, 128)   512         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 4, 4, 128)   512         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 4, 4, 128)    0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 4, 4, 128)   512         ['add_3[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 4, 4, 128)    0           ['activation_9[0][0]',           \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 4, 4, 128)    147584      ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 4, 4, 128)   512         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 4, 4, 128)   512         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 4, 4, 128)   512         ['add_4[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 4, 4, 128)    0           ['activation_11[0][0]',          \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 4, 4, 128)    147584      ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 4, 4, 128)   512         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 4, 4, 128)   512         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 4, 4, 128)   512         ['add_5[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 4, 4, 128)    0           ['activation_13[0][0]',          \n",
            "                                                                  'batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 2, 2, 256)    295168      ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 2, 2, 256)    33024       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 2, 2, 256)    0           ['activation_15[0][0]',          \n",
            "                                                                  'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 2, 2, 256)    590080      ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 2, 2, 256)   1024        ['add_7[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 2, 2, 256)    0           ['activation_17[0][0]',          \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 2, 2, 256)    590080      ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 2, 2, 256)   1024        ['add_8[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 2, 2, 256)    0           ['activation_19[0][0]',          \n",
            "                                                                  'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 2, 2, 256)    590080      ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 2, 2, 256)   1024        ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 2, 2, 256)    0           ['activation_21[0][0]',          \n",
            "                                                                  'batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 2, 2, 256)    590080      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 2, 2, 256)   1024        ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 2, 2, 256)    0           ['activation_23[0][0]',          \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 2, 2, 256)    590080      ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 2, 2, 256)   1024        ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 2, 2, 256)    0           ['activation_25[0][0]',          \n",
            "                                                                  'batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 1, 1, 512)    1180160     ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 1, 1, 512)    131584      ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 1, 1, 512)    0           ['activation_27[0][0]',          \n",
            "                                                                  'batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 1, 1, 512)    2359808     ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 1, 1, 512)   2048        ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 1, 1, 512)    0           ['activation_29[0][0]',          \n",
            "                                                                  'batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 1, 1, 512)    2359808     ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 1, 1, 512)   2048        ['add_14[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 1, 1, 512)    0           ['activation_31[0][0]',          \n",
            "                                                                  'batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 512)   0           ['add_15[0][0]']                 \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 512)          0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 10)           5130        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,319,178\n",
            "Trainable params: 21,296,394\n",
            "Non-trainable params: 22,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet34.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "history_34 = resnet34.fit(\n",
        "    ds_train,\n",
        "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
        "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
        "    epochs=EPOCH,\n",
        "    validation_data=ds_test,\n",
        "    verbose=1,\n",
        "    use_multiprocessing=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml4TR9qQefms",
        "outputId": "ac682534-22ae-4be0-dfa0-ed4af4d75897"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 53s 63ms/step - loss: 1.8484 - accuracy: 0.3759 - val_loss: 1.9755 - val_accuracy: 0.3130\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 1.3139 - accuracy: 0.5335 - val_loss: 1.4691 - val_accuracy: 0.4834\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 1.0209 - accuracy: 0.6440 - val_loss: 1.3421 - val_accuracy: 0.5332\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.7200 - accuracy: 0.7616 - val_loss: 1.4089 - val_accuracy: 0.5284\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.4393 - accuracy: 0.8632 - val_loss: 1.4929 - val_accuracy: 0.5501\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2384 - accuracy: 0.9324 - val_loss: 1.7684 - val_accuracy: 0.5295\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1247 - accuracy: 0.9667 - val_loss: 1.9572 - val_accuracy: 0.5413\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0838 - accuracy: 0.9773 - val_loss: 2.1713 - val_accuracy: 0.5426\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0735 - accuracy: 0.9787 - val_loss: 2.2561 - val_accuracy: 0.5419\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0649 - accuracy: 0.9802 - val_loss: 2.3638 - val_accuracy: 0.5380\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0617 - accuracy: 0.9807 - val_loss: 2.4396 - val_accuracy: 0.5390\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 2.4231 - val_accuracy: 0.5528\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0556 - accuracy: 0.9824 - val_loss: 2.5409 - val_accuracy: 0.5403\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 2.5815 - val_accuracy: 0.5372\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 2.6465 - val_accuracy: 0.5399\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0493 - accuracy: 0.9837 - val_loss: 2.6579 - val_accuracy: 0.5510\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0492 - accuracy: 0.9835 - val_loss: 2.6204 - val_accuracy: 0.5486\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 2.7458 - val_accuracy: 0.5549\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 2.7250 - val_accuracy: 0.5542\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 2.7011 - val_accuracy: 0.5529\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 0.0425 - accuracy: 0.9859 - val_loss: 2.8351 - val_accuracy: 0.5444\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 2.9755 - val_accuracy: 0.5439\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 2.7996 - val_accuracy: 0.5584\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 2.7549 - val_accuracy: 0.5609\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 2.7714 - val_accuracy: 0.5721\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 3.1119 - val_accuracy: 0.5341\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 2.8486 - val_accuracy: 0.5663\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 2.8920 - val_accuracy: 0.5611\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0295 - accuracy: 0.9897 - val_loss: 3.0714 - val_accuracy: 0.5596\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 2.9069 - val_accuracy: 0.5724\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 3.0020 - val_accuracy: 0.5610\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 2.9453 - val_accuracy: 0.5652\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 3.0799 - val_accuracy: 0.5682\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 2.9426 - val_accuracy: 0.5681\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 3.2717 - val_accuracy: 0.5503\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 2.9890 - val_accuracy: 0.5779\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 3.1700 - val_accuracy: 0.5554\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 2.8986 - val_accuracy: 0.5807\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 2.9497 - val_accuracy: 0.5810\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 3.0962 - val_accuracy: 0.5679\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 3.0082 - val_accuracy: 0.5822\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 3.0050 - val_accuracy: 0.5784\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 3.0144 - val_accuracy: 0.5786\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 3.0641 - val_accuracy: 0.5823\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 32s 63ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 3.2065 - val_accuracy: 0.5770\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 2.9816 - val_accuracy: 0.5962\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 3.0208 - val_accuracy: 0.5910\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 3.1228 - val_accuracy: 0.5769\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 32s 63ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 3.1259 - val_accuracy: 0.5853\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 3.1346 - val_accuracy: 0.5827\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 3.1451 - val_accuracy: 0.5842\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 3.2420 - val_accuracy: 0.5841\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 32s 63ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 3.2359 - val_accuracy: 0.5887\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 32s 63ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 3.1847 - val_accuracy: 0.5922\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 3.2446 - val_accuracy: 0.5854\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 3.1743 - val_accuracy: 0.5864\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 3.3605 - val_accuracy: 0.5873\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 3.2867 - val_accuracy: 0.5836\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 3.2586 - val_accuracy: 0.5864\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 3.0666 - val_accuracy: 0.5947\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 3.2025 - val_accuracy: 0.5961\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 3.1779 - val_accuracy: 0.6015\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 32s 63ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.0292 - val_accuracy: 0.6126\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 2.9533e-04 - accuracy: 1.0000 - val_loss: 3.0417 - val_accuracy: 0.6079\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 8.1040e-05 - accuracy: 1.0000 - val_loss: 3.0243 - val_accuracy: 0.6139\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 32s 65ms/step - loss: 3.8228e-05 - accuracy: 1.0000 - val_loss: 3.1199 - val_accuracy: 0.6049\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 3.0773e-05 - accuracy: 1.0000 - val_loss: 3.0928 - val_accuracy: 0.6061\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 32s 63ms/step - loss: 2.7703e-05 - accuracy: 1.0000 - val_loss: 3.0996 - val_accuracy: 0.6129\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 34s 68ms/step - loss: 2.4588e-05 - accuracy: 1.0000 - val_loss: 3.0029 - val_accuracy: 0.6121\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 2.2746e-05 - accuracy: 1.0000 - val_loss: 3.0725 - val_accuracy: 0.6112\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 2.0926e-05 - accuracy: 1.0000 - val_loss: 3.1618 - val_accuracy: 0.6096\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 1.9663e-05 - accuracy: 1.0000 - val_loss: 3.1020 - val_accuracy: 0.6128\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 33s 65ms/step - loss: 1.8483e-05 - accuracy: 1.0000 - val_loss: 3.1009 - val_accuracy: 0.6070\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 1.7540e-05 - accuracy: 1.0000 - val_loss: 3.0957 - val_accuracy: 0.6078\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.6844e-05 - accuracy: 1.0000 - val_loss: 3.0589 - val_accuracy: 0.6101\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.5774e-05 - accuracy: 1.0000 - val_loss: 3.0515 - val_accuracy: 0.6148\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.5361e-05 - accuracy: 1.0000 - val_loss: 3.1683 - val_accuracy: 0.6058\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.4685e-05 - accuracy: 1.0000 - val_loss: 3.0891 - val_accuracy: 0.6130\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.4063e-05 - accuracy: 1.0000 - val_loss: 3.0473 - val_accuracy: 0.6165\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 33s 67ms/step - loss: 1.3721e-05 - accuracy: 1.0000 - val_loss: 3.0880 - val_accuracy: 0.6153\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.3086e-05 - accuracy: 1.0000 - val_loss: 3.1078 - val_accuracy: 0.6116\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.2872e-05 - accuracy: 1.0000 - val_loss: 3.0312 - val_accuracy: 0.6159\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.2324e-05 - accuracy: 1.0000 - val_loss: 3.1206 - val_accuracy: 0.6117\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.2101e-05 - accuracy: 1.0000 - val_loss: 3.0957 - val_accuracy: 0.6144\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 1.1594e-05 - accuracy: 1.0000 - val_loss: 3.0835 - val_accuracy: 0.6143\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.1400e-05 - accuracy: 1.0000 - val_loss: 3.1357 - val_accuracy: 0.6146\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.1065e-05 - accuracy: 1.0000 - val_loss: 3.0620 - val_accuracy: 0.6166\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.0729e-05 - accuracy: 1.0000 - val_loss: 3.1183 - val_accuracy: 0.6126\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.0585e-05 - accuracy: 1.0000 - val_loss: 3.0959 - val_accuracy: 0.6106\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 1.0193e-05 - accuracy: 1.0000 - val_loss: 3.0730 - val_accuracy: 0.6203\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 1.0095e-05 - accuracy: 1.0000 - val_loss: 3.1396 - val_accuracy: 0.6117\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 9.8910e-06 - accuracy: 1.0000 - val_loss: 3.0899 - val_accuracy: 0.6138\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 9.6603e-06 - accuracy: 1.0000 - val_loss: 3.0843 - val_accuracy: 0.6151\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 9.4337e-06 - accuracy: 1.0000 - val_loss: 3.1045 - val_accuracy: 0.6133\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 9.3327e-06 - accuracy: 1.0000 - val_loss: 3.1076 - val_accuracy: 0.6066\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 9.0763e-06 - accuracy: 1.0000 - val_loss: 3.0932 - val_accuracy: 0.6069\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 8.7753e-06 - accuracy: 1.0000 - val_loss: 3.1458 - val_accuracy: 0.6088\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 33s 66ms/step - loss: 8.7814e-06 - accuracy: 1.0000 - val_loss: 3.1175 - val_accuracy: 0.6145\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 8.6365e-06 - accuracy: 1.0000 - val_loss: 3.0783 - val_accuracy: 0.6122\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 8.4581e-06 - accuracy: 1.0000 - val_loss: 3.0986 - val_accuracy: 0.6178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shortcut X\n",
        "비교를 위해 shortcut connection을 제외한 네트워크를 정의합니다."
      ],
      "metadata": {
        "id": "WoaOUHgZo3cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plane 34\n",
        "def plane_block(input,channel,i,stride=1):\n",
        "    x = input\n",
        "    st = stride if i==0 else 1\n",
        "    output = Conv2D(filters=channel,kernel_size=(3,3),strides=st,padding='same')(x)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    output = Conv2D(filters=channel,kernel_size=(3,3),strides=1,padding='same')(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "def PlaneNet34(num_classes = 10):\n",
        "    input_layer = Input(shape=(32, 32, 3))\n",
        "    output = Conv2D(filters=64,kernel_size=(3,3),strides=2,padding='same')(input_layer)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = MaxPooling2D(pool_size=(3,3),strides=2,padding='same')(output)\n",
        "    filter = [64,128,256,512]\n",
        "    num = [3,4,6,3]\n",
        "    s = 1\n",
        "    for n,f in zip(num,filter):\n",
        "        for i in range(n):\n",
        "            output = plane_block(output,f,i,s)\n",
        "        s+=1\n",
        "        if s>=2 : s=2\n",
        "    \n",
        "    output = AveragePooling2D(pool_size=(1,1))(output)\n",
        "    output = Flatten(name='flatten')(output)\n",
        "    output = Dense(num_classes, activation='softmax', name='predictions')(output)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=input_layer, \n",
        "        outputs=output\n",
        "    )\n",
        "    \n",
        "    return model "
      ],
      "metadata": {
        "id": "04vXN1Wlh0s1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "planenet34 = PlaneNet34()\n",
        "planenet34.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAVjtKWCiIne",
        "outputId": "833abf54-0e7b-4eb5-c1ff-c194270986e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 16, 16, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_49 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_50 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_51 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_52 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_53 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_54 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_55 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_56 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_57 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_58 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_59 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_60 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_61 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_62 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_63 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_45 (Activation)  (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_64 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_46 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_65 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_47 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_66 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_48 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_67 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_49 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_68 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_50 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_69 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_51 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_70 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_52 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_71 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_53 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_72 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_54 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_73 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_55 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_74 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_56 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_75 (Bat  (None, 2, 2, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_57 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 1, 1, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_76 (Bat  (None, 1, 1, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_58 (Activation)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_77 (Bat  (None, 1, 1, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_59 (Activation)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_78 (Bat  (None, 1, 1, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_60 (Activation)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_79 (Bat  (None, 1, 1, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_61 (Activation)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_80 (Bat  (None, 1, 1, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_62 (Activation)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_81 (Bat  (None, 1, 1, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_63 (Activation)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 1, 1, 512)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,131,146\n",
            "Trainable params: 21,115,914\n",
            "Non-trainable params: 15,232\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "planenet34.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "plane_history_34 = planenet34.fit(\n",
        "    ds_train,\n",
        "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
        "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
        "    epochs=EPOCH,\n",
        "    validation_data=ds_test,\n",
        "    verbose=1,\n",
        "    use_multiprocessing=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8zYB3foiXMV",
        "outputId": "eb11f322-5c18-4114-c89c-e4c622d2164f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 35s 57ms/step - loss: 2.3306 - accuracy: 0.1352 - val_loss: 2.4070 - val_accuracy: 0.1083\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 28s 56ms/step - loss: 2.0775 - accuracy: 0.2147 - val_loss: 2.0224 - val_accuracy: 0.2503\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 28s 56ms/step - loss: 1.8157 - accuracy: 0.3225 - val_loss: 1.8175 - val_accuracy: 0.3110\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 1.6037 - accuracy: 0.4038 - val_loss: 1.5768 - val_accuracy: 0.4274\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 1.4437 - accuracy: 0.4706 - val_loss: 1.5028 - val_accuracy: 0.4634\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 1.3186 - accuracy: 0.5215 - val_loss: 1.4916 - val_accuracy: 0.4690\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 1.2185 - accuracy: 0.5612 - val_loss: 1.3843 - val_accuracy: 0.5112\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 1.1196 - accuracy: 0.5983 - val_loss: 1.3613 - val_accuracy: 0.5203\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 1.0229 - accuracy: 0.6360 - val_loss: 1.4132 - val_accuracy: 0.5227\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.9193 - accuracy: 0.6746 - val_loss: 1.4712 - val_accuracy: 0.5030\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.8247 - accuracy: 0.7112 - val_loss: 1.8130 - val_accuracy: 0.4582\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.7454 - accuracy: 0.7402 - val_loss: 1.5576 - val_accuracy: 0.5182\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.6464 - accuracy: 0.7748 - val_loss: 1.5845 - val_accuracy: 0.5393\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.5778 - accuracy: 0.8021 - val_loss: 1.7443 - val_accuracy: 0.5162\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.5164 - accuracy: 0.8248 - val_loss: 1.7928 - val_accuracy: 0.5239\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.4612 - accuracy: 0.8433 - val_loss: 1.7666 - val_accuracy: 0.5262\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.4118 - accuracy: 0.8596 - val_loss: 1.9976 - val_accuracy: 0.5032\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.3708 - accuracy: 0.8741 - val_loss: 1.9560 - val_accuracy: 0.5278\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.3380 - accuracy: 0.8859 - val_loss: 1.9541 - val_accuracy: 0.5422\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.3095 - accuracy: 0.8974 - val_loss: 2.1059 - val_accuracy: 0.5245\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.2792 - accuracy: 0.9052 - val_loss: 2.1167 - val_accuracy: 0.5212\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.2594 - accuracy: 0.9120 - val_loss: 2.1543 - val_accuracy: 0.5091\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.2424 - accuracy: 0.9180 - val_loss: 2.1854 - val_accuracy: 0.5264\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.2256 - accuracy: 0.9246 - val_loss: 2.1368 - val_accuracy: 0.5285\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.2110 - accuracy: 0.9295 - val_loss: 2.3346 - val_accuracy: 0.5235\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1925 - accuracy: 0.9352 - val_loss: 2.2759 - val_accuracy: 0.5301\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1809 - accuracy: 0.9374 - val_loss: 2.3027 - val_accuracy: 0.5440\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1728 - accuracy: 0.9405 - val_loss: 2.3794 - val_accuracy: 0.5308\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1680 - accuracy: 0.9436 - val_loss: 2.2125 - val_accuracy: 0.5447\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.1600 - accuracy: 0.9439 - val_loss: 2.4238 - val_accuracy: 0.5221\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1486 - accuracy: 0.9496 - val_loss: 2.4352 - val_accuracy: 0.5270\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1433 - accuracy: 0.9508 - val_loss: 2.4949 - val_accuracy: 0.5275\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1375 - accuracy: 0.9524 - val_loss: 2.4750 - val_accuracy: 0.5226\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1275 - accuracy: 0.9566 - val_loss: 2.4344 - val_accuracy: 0.5383\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.1302 - accuracy: 0.9558 - val_loss: 2.3845 - val_accuracy: 0.5380\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1240 - accuracy: 0.9574 - val_loss: 2.5061 - val_accuracy: 0.5286\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1181 - accuracy: 0.9596 - val_loss: 2.7172 - val_accuracy: 0.5146\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1086 - accuracy: 0.9632 - val_loss: 2.5160 - val_accuracy: 0.5393\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1105 - accuracy: 0.9621 - val_loss: 2.5387 - val_accuracy: 0.5285\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1075 - accuracy: 0.9622 - val_loss: 2.5411 - val_accuracy: 0.5344\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.1023 - accuracy: 0.9652 - val_loss: 2.5144 - val_accuracy: 0.5389\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.1007 - accuracy: 0.9646 - val_loss: 2.5926 - val_accuracy: 0.5528\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0964 - accuracy: 0.9670 - val_loss: 2.4873 - val_accuracy: 0.5452\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0948 - accuracy: 0.9666 - val_loss: 2.5153 - val_accuracy: 0.5485\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.0911 - accuracy: 0.9686 - val_loss: 2.5115 - val_accuracy: 0.5471\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0856 - accuracy: 0.9699 - val_loss: 2.6057 - val_accuracy: 0.5485\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0876 - accuracy: 0.9704 - val_loss: 2.5317 - val_accuracy: 0.5468\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0853 - accuracy: 0.9708 - val_loss: 2.7186 - val_accuracy: 0.5310\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0851 - accuracy: 0.9705 - val_loss: 2.5229 - val_accuracy: 0.5453\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0808 - accuracy: 0.9717 - val_loss: 2.7097 - val_accuracy: 0.5278\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0799 - accuracy: 0.9724 - val_loss: 2.6600 - val_accuracy: 0.5370\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0782 - accuracy: 0.9738 - val_loss: 2.5796 - val_accuracy: 0.5541\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0743 - accuracy: 0.9751 - val_loss: 2.5525 - val_accuracy: 0.5551\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0736 - accuracy: 0.9753 - val_loss: 2.6393 - val_accuracy: 0.5462\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0735 - accuracy: 0.9748 - val_loss: 2.6614 - val_accuracy: 0.5520\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 28s 57ms/step - loss: 0.0728 - accuracy: 0.9746 - val_loss: 2.6467 - val_accuracy: 0.5463\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0681 - accuracy: 0.9767 - val_loss: 2.6494 - val_accuracy: 0.5390\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 31s 63ms/step - loss: 0.0638 - accuracy: 0.9782 - val_loss: 2.8116 - val_accuracy: 0.5396\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 2.6394 - val_accuracy: 0.5582\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0653 - accuracy: 0.9778 - val_loss: 2.6495 - val_accuracy: 0.5508\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0669 - accuracy: 0.9766 - val_loss: 2.6413 - val_accuracy: 0.5503\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0629 - accuracy: 0.9782 - val_loss: 2.7232 - val_accuracy: 0.5394\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0617 - accuracy: 0.9791 - val_loss: 2.6787 - val_accuracy: 0.5433\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0601 - accuracy: 0.9786 - val_loss: 2.6061 - val_accuracy: 0.5576\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0610 - accuracy: 0.9790 - val_loss: 2.6920 - val_accuracy: 0.5428\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0621 - accuracy: 0.9793 - val_loss: 2.5685 - val_accuracy: 0.5606\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 2.7680 - val_accuracy: 0.5467\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0579 - accuracy: 0.9802 - val_loss: 2.6189 - val_accuracy: 0.5528\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0546 - accuracy: 0.9815 - val_loss: 2.6446 - val_accuracy: 0.5600\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0555 - accuracy: 0.9815 - val_loss: 2.7123 - val_accuracy: 0.5466\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0556 - accuracy: 0.9819 - val_loss: 2.5884 - val_accuracy: 0.5697\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0544 - accuracy: 0.9813 - val_loss: 2.6718 - val_accuracy: 0.5473\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0547 - accuracy: 0.9817 - val_loss: 2.6537 - val_accuracy: 0.5505\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0511 - accuracy: 0.9829 - val_loss: 2.6604 - val_accuracy: 0.5567\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 2.6536 - val_accuracy: 0.5546\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0499 - accuracy: 0.9829 - val_loss: 2.5596 - val_accuracy: 0.5629\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0490 - accuracy: 0.9835 - val_loss: 2.6509 - val_accuracy: 0.5512\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 2.6907 - val_accuracy: 0.5566\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 2.7081 - val_accuracy: 0.5638\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0457 - accuracy: 0.9847 - val_loss: 2.7655 - val_accuracy: 0.5571\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 2.7709 - val_accuracy: 0.5535\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 2.8952 - val_accuracy: 0.5427\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0434 - accuracy: 0.9854 - val_loss: 2.6830 - val_accuracy: 0.5576\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 2.6772 - val_accuracy: 0.5614\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0426 - accuracy: 0.9852 - val_loss: 2.7009 - val_accuracy: 0.5645\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 2.8590 - val_accuracy: 0.5451\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 31s 62ms/step - loss: 0.0451 - accuracy: 0.9847 - val_loss: 2.6488 - val_accuracy: 0.5585\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0417 - accuracy: 0.9863 - val_loss: 2.6064 - val_accuracy: 0.5636\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0422 - accuracy: 0.9858 - val_loss: 2.7450 - val_accuracy: 0.5552\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0429 - accuracy: 0.9859 - val_loss: 2.6257 - val_accuracy: 0.5665\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 2.7376 - val_accuracy: 0.5601\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0418 - accuracy: 0.9856 - val_loss: 2.6731 - val_accuracy: 0.5706\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 2.7308 - val_accuracy: 0.5611\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 2.8330 - val_accuracy: 0.5571\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 2.7448 - val_accuracy: 0.5653\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 2.7677 - val_accuracy: 0.5551\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 0.0353 - accuracy: 0.9881 - val_loss: 2.8822 - val_accuracy: 0.5490\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 2.7980 - val_accuracy: 0.5704\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 2.6676 - val_accuracy: 0.5759\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 2.7311 - val_accuracy: 0.5611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시각화\n",
        "loss가 확실히 빠르게 감소합니다."
      ],
      "metadata": {
        "id": "9HlOvR5XoK3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history_34.history['loss'], 'r')\n",
        "plt.plot(plane_history_34.history['loss'], 'b')\n",
        "plt.title('Model training loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['ResNet34', 'PlaneNet_34'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cpdiK4PGnRgX",
        "outputId": "905355e8-4d68-4eba-8f61-4bd65a72161f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet50\n",
        "이번엔 모델 구조를 자세히 파악하기 위해 반복문 없이 블록을 쌓도록 했습니다."
      ],
      "metadata": {
        "id": "mV3AAnrLpeUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bottleneck_block(input,channel,stride=1):\n",
        "    x = input\n",
        "    shortcut = input\n",
        "    output = Conv2D(filters=channel,kernel_size=(1,1),strides=stride,padding='same')(x)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    output = Conv2D(filters=channel,kernel_size=(3,3),strides=1,padding='same')(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    output = Conv2D(filters=(channel*4),kernel_size=(1,1),strides=1,padding='same')(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "    # 이전 레이어로부터 처음 받았다면 크기조절 필요\n",
        "    if stride != 1:\n",
        "        shortcut = Conv2D(filters=(channel*4),kernel_size=(1,1),strides=2,padding='same')(shortcut)\n",
        "    else:\n",
        "        shortcut = Conv2D(filters=(channel*4),kernel_size=(1,1),strides=1,padding='same')(shortcut)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    output = Add()([output,shortcut])\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "oeXVi3CjdlYv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이어의 첫번째 블록에서 down sampling이 일어납니다."
      ],
      "metadata": {
        "id": "4PJevwIhp1Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(num_classes = 10):\n",
        "    input_layer = Input(shape=(32, 32, 3))\n",
        "    output = Conv2D(filters=64,kernel_size=(3,3),strides=2,padding='same')(input_layer)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = MaxPooling2D(pool_size=(3,3),strides=2,padding='same')(output)\n",
        "\n",
        "    output = bottleneck_block(output,64,1)\n",
        "    output = bottleneck_block(output,64,1)\n",
        "    output = bottleneck_block(output,64,1)\n",
        "\n",
        "    output = bottleneck_block(output,128,2)\n",
        "    output = bottleneck_block(output,128,1)\n",
        "    output = bottleneck_block(output,128,1)\n",
        "    output = bottleneck_block(output,128,1)\n",
        "\n",
        "    output = bottleneck_block(output,256,2)\n",
        "    output = bottleneck_block(output,256,1)\n",
        "    output = bottleneck_block(output,256,1)\n",
        "    output = bottleneck_block(output,256,1)\n",
        "    output = bottleneck_block(output,256,1)\n",
        "    output = bottleneck_block(output,256,1)\n",
        "\n",
        "    output = bottleneck_block(output,512,2)\n",
        "    output = bottleneck_block(output,512,1)\n",
        "    output = bottleneck_block(output,512,1)\n",
        "\n",
        "    output = AveragePooling2D(pool_size=(1,1))(output)\n",
        "    output = Flatten(name='flatten')(output)\n",
        "    output = Dense(num_classes, activation='softmax', name='predictions')(output)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=input_layer, \n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "e3G9lCOOiKMu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = ResNet50()\n",
        "resnet50.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVqZLzB_jXXO",
        "outputId": "72ff5c39-5153-49ed-a2db-ad5b13b6817a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 16, 16, 64)   1792        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 16, 16, 64)  256         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 8, 8, 64)     4160        ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 8, 8, 64)    256         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 8, 8, 64)    256         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 8, 8, 256)    16640       ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 8, 8, 256)    16640       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 8, 8, 256)    0           ['activation_66[0][0]',          \n",
            "                                                                  'batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 8, 8, 64)     16448       ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 8, 8, 64)    256         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 8, 8, 64)    256         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 8, 8, 256)    16640       ['activation_68[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 8, 8, 256)    65792       ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 8, 8, 256)    0           ['activation_69[0][0]',          \n",
            "                                                                  'batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 8, 8, 64)     16448       ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 8, 8, 64)    256         ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 8, 8, 64)    256         ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 8, 8, 256)    16640       ['activation_71[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 8, 8, 256)    65792       ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 8, 8, 256)    0           ['activation_72[0][0]',          \n",
            "                                                                  'batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 4, 4, 128)    32896       ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 4, 4, 128)   512         ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 4, 4, 128)   512         ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 4, 4, 512)    131584      ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 4, 4, 512)    0           ['activation_75[0][0]',          \n",
            "                                                                  'batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 4, 4, 128)    65664       ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 4, 4, 128)   512         ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_76[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 4, 4, 128)   512         ['conv2d_87[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 4, 4, 512)   2048        ['conv2d_88[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 4, 4, 512)    262656      ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 4, 4, 512)   2048        ['conv2d_89[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 4, 4, 512)    0           ['activation_78[0][0]',          \n",
            "                                                                  'batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 4, 4, 128)    65664       ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 4, 4, 128)   512         ['conv2d_90[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 4, 4, 128)   512         ['conv2d_91[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 4, 4, 512)   2048        ['conv2d_92[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 4, 4, 512)    262656      ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 4, 4, 512)   2048        ['conv2d_93[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 4, 4, 512)    0           ['activation_81[0][0]',          \n",
            "                                                                  'batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 4, 4, 128)    65664       ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 4, 4, 128)   512         ['conv2d_94[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_82[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 4, 4, 128)   512         ['conv2d_95[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 4, 4, 512)   2048        ['conv2d_96[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 4, 4, 512)    262656      ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 4, 4, 512)    0           ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 4, 4, 512)   2048        ['conv2d_97[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 4, 4, 512)    0           ['activation_84[0][0]',          \n",
            "                                                                  'batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 2, 2, 256)    131328      ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 2, 2, 256)   1024        ['conv2d_98[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_85[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 2, 2, 256)   1024        ['conv2d_99[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 2, 2, 1024)   525312      ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 2, 2, 1024)   0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 2, 2, 1024)   0           ['activation_87[0][0]',          \n",
            "                                                                  'batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 2, 2, 256)    262400      ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 2, 2, 256)   1024        ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 2, 2, 256)   1024        ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 2, 2, 1024)   1049600     ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 2, 2, 1024)   0           ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 2, 2, 1024)   0           ['activation_90[0][0]',          \n",
            "                                                                  'batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 2, 2, 256)    262400      ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 2, 2, 256)   1024        ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_91[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 2, 2, 256)   1024        ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_108[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 2, 2, 1024)   1049600     ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 2, 2, 1024)   0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_109[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 2, 2, 1024)   0           ['activation_93[0][0]',          \n",
            "                                                                  'batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 2, 2, 256)    262400      ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 2, 2, 256)   1024        ['conv2d_110[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_94[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 2, 2, 256)   1024        ['conv2d_111[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_95[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_112[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 2, 2, 1024)   1049600     ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 2, 2, 1024)   0           ['batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 2, 2, 1024)   0           ['activation_96[0][0]',          \n",
            "                                                                  'batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 2, 2, 256)    262400      ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 2, 2, 256)   1024        ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_97[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 2, 2, 256)   1024        ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 2, 2, 1024)   1049600     ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 2, 2, 1024)   0           ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 2, 2, 1024)   0           ['activation_99[0][0]',          \n",
            "                                                                  'batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 2, 2, 256)    262400      ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 2, 2, 256)   1024        ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 2, 2, 256)   1024        ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_101[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 2, 2, 1024)   1049600     ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 2, 2, 1024)   0           ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 2, 2, 1024)   0           ['activation_102[0][0]',         \n",
            "                                                                  'batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 1, 1, 512)    524800      ['add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 1, 1, 512)   2048        ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 1, 1, 512)    2359808     ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 1, 1, 512)   2048        ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 1, 1, 2048)   1050624     ['activation_104[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 1, 1, 2048)   2099200     ['add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 1, 1, 2048)   0           ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_125[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 1, 1, 2048)   0           ['activation_105[0][0]',         \n",
            "                                                                  'batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 1, 1, 512)    1049088     ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 1, 1, 512)   2048        ['conv2d_126[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 1, 1, 512)    2359808     ['activation_106[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 1, 1, 512)   2048        ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 1, 1, 2048)   1050624     ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 1, 1, 2048)   4196352     ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 1, 1, 2048)   0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_129[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, 1, 1, 2048)   0           ['activation_108[0][0]',         \n",
            "                                                                  'batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 1, 1, 512)    1049088     ['add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 1, 1, 512)   2048        ['conv2d_130[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 1, 1, 512)    2359808     ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 1, 1, 512)   2048        ['conv2d_131[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 1, 1, 2048)   1050624     ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_132[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 1, 1, 2048)   4196352     ['add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 1, 1, 2048)   0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_133[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, 1, 1, 2048)   0           ['activation_111[0][0]',         \n",
            "                                                                  'batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 1, 1, 2048)  0           ['add_31[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 10)           20490       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,205,834\n",
            "Trainable params: 38,130,186\n",
            "Non-trainable params: 75,648\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "history_50 = resnet50.fit(\n",
        "    ds_train,\n",
        "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
        "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
        "    epochs=EPOCH,\n",
        "    validation_data=ds_test,\n",
        "    verbose=1,\n",
        "    use_multiprocessing=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHFCkO_Qst3e",
        "outputId": "74c98907-5717-4c70-806d-2e50277693b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 69s 111ms/step - loss: 2.1993 - accuracy: 0.2756 - val_loss: 2.0642 - val_accuracy: 0.2654\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 55s 110ms/step - loss: 1.7767 - accuracy: 0.3798 - val_loss: 1.8951 - val_accuracy: 0.3752\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 1.5871 - accuracy: 0.4416 - val_loss: 1.8556 - val_accuracy: 0.4011\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 1.4324 - accuracy: 0.4921 - val_loss: 1.5775 - val_accuracy: 0.4507\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 1.2821 - accuracy: 0.5426 - val_loss: 1.5137 - val_accuracy: 0.4852\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 1.1283 - accuracy: 0.6008 - val_loss: 1.3828 - val_accuracy: 0.5266\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.9583 - accuracy: 0.6620 - val_loss: 1.3440 - val_accuracy: 0.5436\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.7664 - accuracy: 0.7346 - val_loss: 1.4830 - val_accuracy: 0.5324\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 57s 115ms/step - loss: 0.5581 - accuracy: 0.8097 - val_loss: 1.4663 - val_accuracy: 0.5615\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.3727 - accuracy: 0.8755 - val_loss: 1.7115 - val_accuracy: 0.5522\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.2451 - accuracy: 0.9202 - val_loss: 1.7726 - val_accuracy: 0.5791\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.1702 - accuracy: 0.9436 - val_loss: 1.9774 - val_accuracy: 0.5511\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.1420 - accuracy: 0.9527 - val_loss: 2.1321 - val_accuracy: 0.5530\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.1254 - accuracy: 0.9565 - val_loss: 2.3499 - val_accuracy: 0.5397\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.1161 - accuracy: 0.9604 - val_loss: 2.1895 - val_accuracy: 0.5725\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.1087 - accuracy: 0.9637 - val_loss: 2.3526 - val_accuracy: 0.5743\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.1067 - accuracy: 0.9642 - val_loss: 2.4102 - val_accuracy: 0.5643\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0968 - accuracy: 0.9673 - val_loss: 2.5113 - val_accuracy: 0.5497\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0906 - accuracy: 0.9690 - val_loss: 2.4091 - val_accuracy: 0.5838\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0873 - accuracy: 0.9696 - val_loss: 2.4854 - val_accuracy: 0.5732\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0866 - accuracy: 0.9696 - val_loss: 2.5524 - val_accuracy: 0.5682\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0811 - accuracy: 0.9710 - val_loss: 2.7573 - val_accuracy: 0.5605\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0795 - accuracy: 0.9730 - val_loss: 2.6999 - val_accuracy: 0.5705\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0731 - accuracy: 0.9746 - val_loss: 2.6314 - val_accuracy: 0.5723\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0684 - accuracy: 0.9764 - val_loss: 2.6001 - val_accuracy: 0.5761\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0686 - accuracy: 0.9765 - val_loss: 2.6311 - val_accuracy: 0.5845\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0652 - accuracy: 0.9776 - val_loss: 3.0057 - val_accuracy: 0.5628\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0638 - accuracy: 0.9783 - val_loss: 2.6628 - val_accuracy: 0.5848\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0612 - accuracy: 0.9784 - val_loss: 2.7373 - val_accuracy: 0.5811\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0562 - accuracy: 0.9802 - val_loss: 2.7618 - val_accuracy: 0.5819\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0557 - accuracy: 0.9807 - val_loss: 2.8958 - val_accuracy: 0.5800\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0534 - accuracy: 0.9817 - val_loss: 2.8163 - val_accuracy: 0.5788\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0488 - accuracy: 0.9827 - val_loss: 2.8091 - val_accuracy: 0.5907\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0497 - accuracy: 0.9826 - val_loss: 2.7774 - val_accuracy: 0.6059\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 2.7711 - val_accuracy: 0.5892\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0434 - accuracy: 0.9853 - val_loss: 2.7690 - val_accuracy: 0.6069\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0422 - accuracy: 0.9850 - val_loss: 2.8752 - val_accuracy: 0.5903\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0429 - accuracy: 0.9851 - val_loss: 3.8663 - val_accuracy: 0.5336\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0443 - accuracy: 0.9845 - val_loss: 3.0498 - val_accuracy: 0.5814\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0423 - accuracy: 0.9857 - val_loss: 2.9512 - val_accuracy: 0.5965\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 3.0048 - val_accuracy: 0.5949\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 2.9946 - val_accuracy: 0.5927\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 3.0773 - val_accuracy: 0.5944\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 3.0758 - val_accuracy: 0.5883\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 2.9704 - val_accuracy: 0.6023\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 2.9307 - val_accuracy: 0.6029\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0344 - accuracy: 0.9880 - val_loss: 3.0175 - val_accuracy: 0.5978\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 2.9364 - val_accuracy: 0.6062\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 3.1737 - val_accuracy: 0.5887\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 2.8460 - val_accuracy: 0.6217\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 3.0428 - val_accuracy: 0.6028\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 2.9109 - val_accuracy: 0.6113\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 3.1961 - val_accuracy: 0.5957\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 3.1468 - val_accuracy: 0.6018\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 3.1282 - val_accuracy: 0.6103\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 3.2821 - val_accuracy: 0.5887\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 3.2071 - val_accuracy: 0.5969\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 3.1335 - val_accuracy: 0.6059\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 3.1270 - val_accuracy: 0.6061\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 2.9798 - val_accuracy: 0.6240\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 3.2110 - val_accuracy: 0.5992\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 3.0992 - val_accuracy: 0.6166\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 3.1269 - val_accuracy: 0.6165\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 3.1286 - val_accuracy: 0.6249\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 3.3690 - val_accuracy: 0.6163\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 3.1223 - val_accuracy: 0.6178\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 3.2722 - val_accuracy: 0.6219\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 3.3598 - val_accuracy: 0.6035\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 3.2241 - val_accuracy: 0.6138\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 3.1490 - val_accuracy: 0.6203\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 3.3883 - val_accuracy: 0.6073\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 3.3216 - val_accuracy: 0.6165\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 57s 115ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 3.2830 - val_accuracy: 0.6269\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 3.2835 - val_accuracy: 0.6251\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 3.5954 - val_accuracy: 0.5995\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 3.1925 - val_accuracy: 0.6245\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 3.4204 - val_accuracy: 0.6151\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 3.2217 - val_accuracy: 0.6269\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 9.7325e-04 - accuracy: 0.9998 - val_loss: 3.2171 - val_accuracy: 0.6324\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.7627e-04 - accuracy: 1.0000 - val_loss: 3.0926 - val_accuracy: 0.6431\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 4.6001e-05 - accuracy: 1.0000 - val_loss: 3.1488 - val_accuracy: 0.6437\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 3.2287e-05 - accuracy: 1.0000 - val_loss: 3.0970 - val_accuracy: 0.6404\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 2.6629e-05 - accuracy: 1.0000 - val_loss: 3.1845 - val_accuracy: 0.6360\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 2.3949e-05 - accuracy: 1.0000 - val_loss: 3.0822 - val_accuracy: 0.6443\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 2.1490e-05 - accuracy: 1.0000 - val_loss: 3.1463 - val_accuracy: 0.6444\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 1.9828e-05 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.6403\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.8565e-05 - accuracy: 1.0000 - val_loss: 3.1160 - val_accuracy: 0.6412\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.7308e-05 - accuracy: 1.0000 - val_loss: 3.0993 - val_accuracy: 0.6474\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.6388e-05 - accuracy: 1.0000 - val_loss: 3.1295 - val_accuracy: 0.6373\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.5532e-05 - accuracy: 1.0000 - val_loss: 3.0843 - val_accuracy: 0.6382\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.4796e-05 - accuracy: 1.0000 - val_loss: 3.1555 - val_accuracy: 0.6407\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.3928e-05 - accuracy: 1.0000 - val_loss: 3.1881 - val_accuracy: 0.6343\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.3658e-05 - accuracy: 1.0000 - val_loss: 3.1485 - val_accuracy: 0.6360\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.2887e-05 - accuracy: 1.0000 - val_loss: 3.0949 - val_accuracy: 0.6483\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.2486e-05 - accuracy: 1.0000 - val_loss: 3.1088 - val_accuracy: 0.6374\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.1955e-05 - accuracy: 1.0000 - val_loss: 3.2287 - val_accuracy: 0.6322\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.1697e-05 - accuracy: 1.0000 - val_loss: 3.0990 - val_accuracy: 0.6444\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 58s 115ms/step - loss: 1.1114e-05 - accuracy: 1.0000 - val_loss: 3.2136 - val_accuracy: 0.6427\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.1134e-05 - accuracy: 1.0000 - val_loss: 3.1216 - val_accuracy: 0.6380\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 1.0537e-05 - accuracy: 1.0000 - val_loss: 3.1403 - val_accuracy: 0.6391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shortcut X\n",
        "역시 shortcut connection을 제외한 네트워크를 정의합니다."
      ],
      "metadata": {
        "id": "uA8jyTvsqCcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plane_bottleneck_block(input,channel,stride=1):\n",
        "    x = input\n",
        "    output = Conv2D(filters=channel,kernel_size=(1,1),strides=stride,padding='same')(x)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    output = Conv2D(filters=channel,kernel_size=(3,3),strides=1,padding='same')(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    output = Conv2D(filters=(channel*4),kernel_size=(1,1),strides=1,padding='same')(output)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation('relu')(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "def PlaneNet50(num_classes = 10):\n",
        "    input_layer = Input(shape=(32, 32, 3))\n",
        "    output = Conv2D(filters=64,kernel_size=(3,3),strides=2,padding='same')(input_layer)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = MaxPooling2D(pool_size=(3,3),strides=2,padding='same')(output)\n",
        "\n",
        "    output = plane_bottleneck_block(output,64,1)\n",
        "    output = plane_bottleneck_block(output,64,1)\n",
        "    output = plane_bottleneck_block(output,64,1)\n",
        "\n",
        "    output = plane_bottleneck_block(output,128,2)\n",
        "    output = plane_bottleneck_block(output,128,1)\n",
        "    output = plane_bottleneck_block(output,128,1)\n",
        "    output = plane_bottleneck_block(output,128,1)\n",
        "\n",
        "    output = plane_bottleneck_block(output,256,2)\n",
        "    output = plane_bottleneck_block(output,256,1)\n",
        "    output = plane_bottleneck_block(output,256,1)\n",
        "    output = plane_bottleneck_block(output,256,1)\n",
        "    output = plane_bottleneck_block(output,256,1)\n",
        "    output = plane_bottleneck_block(output,256,1)\n",
        "\n",
        "    output = plane_bottleneck_block(output,512,2)\n",
        "    output = plane_bottleneck_block(output,512,1)\n",
        "    output = plane_bottleneck_block(output,512,1)\n",
        "\n",
        "    output = AveragePooling2D(pool_size=(1,1))(output)\n",
        "    output = Flatten(name='flatten')(output)\n",
        "    output = Dense(num_classes, activation='softmax', name='predictions')(output)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=input_layer, \n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "IiIDegWJs6Ke"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "planenet50 = PlaneNet50()\n",
        "planenet50.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJmG4puPtblX",
        "outputId": "b28ad2ee-3797-4a27-c94b-e4a2d4e6c451"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_134 (Conv2D)         (None, 16, 16, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_147 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_135 (Conv2D)         (None, 8, 8, 64)          4160      \n",
            "                                                                 \n",
            " batch_normalization_148 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_112 (Activation)  (None, 8, 8, 64)         0         \n",
            "                                                                 \n",
            " conv2d_136 (Conv2D)         (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_149 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_113 (Activation)  (None, 8, 8, 64)         0         \n",
            "                                                                 \n",
            " conv2d_137 (Conv2D)         (None, 8, 8, 256)         16640     \n",
            "                                                                 \n",
            " batch_normalization_150 (Ba  (None, 8, 8, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_114 (Activation)  (None, 8, 8, 256)        0         \n",
            "                                                                 \n",
            " conv2d_138 (Conv2D)         (None, 8, 8, 64)          16448     \n",
            "                                                                 \n",
            " batch_normalization_151 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_115 (Activation)  (None, 8, 8, 64)         0         \n",
            "                                                                 \n",
            " conv2d_139 (Conv2D)         (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_152 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_116 (Activation)  (None, 8, 8, 64)         0         \n",
            "                                                                 \n",
            " conv2d_140 (Conv2D)         (None, 8, 8, 256)         16640     \n",
            "                                                                 \n",
            " batch_normalization_153 (Ba  (None, 8, 8, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_117 (Activation)  (None, 8, 8, 256)        0         \n",
            "                                                                 \n",
            " conv2d_141 (Conv2D)         (None, 8, 8, 64)          16448     \n",
            "                                                                 \n",
            " batch_normalization_154 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_118 (Activation)  (None, 8, 8, 64)         0         \n",
            "                                                                 \n",
            " conv2d_142 (Conv2D)         (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_155 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_119 (Activation)  (None, 8, 8, 64)         0         \n",
            "                                                                 \n",
            " conv2d_143 (Conv2D)         (None, 8, 8, 256)         16640     \n",
            "                                                                 \n",
            " batch_normalization_156 (Ba  (None, 8, 8, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_120 (Activation)  (None, 8, 8, 256)        0         \n",
            "                                                                 \n",
            " conv2d_144 (Conv2D)         (None, 4, 4, 128)         32896     \n",
            "                                                                 \n",
            " batch_normalization_157 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_121 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_158 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_122 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_146 (Conv2D)         (None, 4, 4, 512)         66048     \n",
            "                                                                 \n",
            " batch_normalization_159 (Ba  (None, 4, 4, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_123 (Activation)  (None, 4, 4, 512)        0         \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 4, 4, 128)         65664     \n",
            "                                                                 \n",
            " batch_normalization_160 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_124 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_148 (Conv2D)         (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_161 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_125 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_149 (Conv2D)         (None, 4, 4, 512)         66048     \n",
            "                                                                 \n",
            " batch_normalization_162 (Ba  (None, 4, 4, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_126 (Activation)  (None, 4, 4, 512)        0         \n",
            "                                                                 \n",
            " conv2d_150 (Conv2D)         (None, 4, 4, 128)         65664     \n",
            "                                                                 \n",
            " batch_normalization_163 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_127 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_151 (Conv2D)         (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_164 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_128 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_152 (Conv2D)         (None, 4, 4, 512)         66048     \n",
            "                                                                 \n",
            " batch_normalization_165 (Ba  (None, 4, 4, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_129 (Activation)  (None, 4, 4, 512)        0         \n",
            "                                                                 \n",
            " conv2d_153 (Conv2D)         (None, 4, 4, 128)         65664     \n",
            "                                                                 \n",
            " batch_normalization_166 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_130 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_154 (Conv2D)         (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_167 (Ba  (None, 4, 4, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_131 (Activation)  (None, 4, 4, 128)        0         \n",
            "                                                                 \n",
            " conv2d_155 (Conv2D)         (None, 4, 4, 512)         66048     \n",
            "                                                                 \n",
            " batch_normalization_168 (Ba  (None, 4, 4, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_132 (Activation)  (None, 4, 4, 512)        0         \n",
            "                                                                 \n",
            " conv2d_156 (Conv2D)         (None, 2, 2, 256)         131328    \n",
            "                                                                 \n",
            " batch_normalization_169 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_133 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_157 (Conv2D)         (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_170 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_134 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_158 (Conv2D)         (None, 2, 2, 1024)        263168    \n",
            "                                                                 \n",
            " batch_normalization_171 (Ba  (None, 2, 2, 1024)       4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_135 (Activation)  (None, 2, 2, 1024)       0         \n",
            "                                                                 \n",
            " conv2d_159 (Conv2D)         (None, 2, 2, 256)         262400    \n",
            "                                                                 \n",
            " batch_normalization_172 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_136 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_160 (Conv2D)         (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_173 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_137 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_161 (Conv2D)         (None, 2, 2, 1024)        263168    \n",
            "                                                                 \n",
            " batch_normalization_174 (Ba  (None, 2, 2, 1024)       4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_138 (Activation)  (None, 2, 2, 1024)       0         \n",
            "                                                                 \n",
            " conv2d_162 (Conv2D)         (None, 2, 2, 256)         262400    \n",
            "                                                                 \n",
            " batch_normalization_175 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_139 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_163 (Conv2D)         (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_176 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_140 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_164 (Conv2D)         (None, 2, 2, 1024)        263168    \n",
            "                                                                 \n",
            " batch_normalization_177 (Ba  (None, 2, 2, 1024)       4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_141 (Activation)  (None, 2, 2, 1024)       0         \n",
            "                                                                 \n",
            " conv2d_165 (Conv2D)         (None, 2, 2, 256)         262400    \n",
            "                                                                 \n",
            " batch_normalization_178 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_142 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_166 (Conv2D)         (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_179 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_143 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_167 (Conv2D)         (None, 2, 2, 1024)        263168    \n",
            "                                                                 \n",
            " batch_normalization_180 (Ba  (None, 2, 2, 1024)       4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_144 (Activation)  (None, 2, 2, 1024)       0         \n",
            "                                                                 \n",
            " conv2d_168 (Conv2D)         (None, 2, 2, 256)         262400    \n",
            "                                                                 \n",
            " batch_normalization_181 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_145 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_169 (Conv2D)         (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_182 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_146 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_170 (Conv2D)         (None, 2, 2, 1024)        263168    \n",
            "                                                                 \n",
            " batch_normalization_183 (Ba  (None, 2, 2, 1024)       4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_147 (Activation)  (None, 2, 2, 1024)       0         \n",
            "                                                                 \n",
            " conv2d_171 (Conv2D)         (None, 2, 2, 256)         262400    \n",
            "                                                                 \n",
            " batch_normalization_184 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_148 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_172 (Conv2D)         (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_185 (Ba  (None, 2, 2, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_149 (Activation)  (None, 2, 2, 256)        0         \n",
            "                                                                 \n",
            " conv2d_173 (Conv2D)         (None, 2, 2, 1024)        263168    \n",
            "                                                                 \n",
            " batch_normalization_186 (Ba  (None, 2, 2, 1024)       4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_150 (Activation)  (None, 2, 2, 1024)       0         \n",
            "                                                                 \n",
            " conv2d_174 (Conv2D)         (None, 1, 1, 512)         524800    \n",
            "                                                                 \n",
            " batch_normalization_187 (Ba  (None, 1, 1, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_151 (Activation)  (None, 1, 1, 512)        0         \n",
            "                                                                 \n",
            " conv2d_175 (Conv2D)         (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_188 (Ba  (None, 1, 1, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_152 (Activation)  (None, 1, 1, 512)        0         \n",
            "                                                                 \n",
            " conv2d_176 (Conv2D)         (None, 1, 1, 2048)        1050624   \n",
            "                                                                 \n",
            " batch_normalization_189 (Ba  (None, 1, 1, 2048)       8192      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_153 (Activation)  (None, 1, 1, 2048)       0         \n",
            "                                                                 \n",
            " conv2d_177 (Conv2D)         (None, 1, 1, 512)         1049088   \n",
            "                                                                 \n",
            " batch_normalization_190 (Ba  (None, 1, 1, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_154 (Activation)  (None, 1, 1, 512)        0         \n",
            "                                                                 \n",
            " conv2d_178 (Conv2D)         (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_191 (Ba  (None, 1, 1, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_155 (Activation)  (None, 1, 1, 512)        0         \n",
            "                                                                 \n",
            " conv2d_179 (Conv2D)         (None, 1, 1, 2048)        1050624   \n",
            "                                                                 \n",
            " batch_normalization_192 (Ba  (None, 1, 1, 2048)       8192      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_156 (Activation)  (None, 1, 1, 2048)       0         \n",
            "                                                                 \n",
            " conv2d_180 (Conv2D)         (None, 1, 1, 512)         1049088   \n",
            "                                                                 \n",
            " batch_normalization_193 (Ba  (None, 1, 1, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_157 (Activation)  (None, 1, 1, 512)        0         \n",
            "                                                                 \n",
            " conv2d_181 (Conv2D)         (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_194 (Ba  (None, 1, 1, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_158 (Activation)  (None, 1, 1, 512)        0         \n",
            "                                                                 \n",
            " conv2d_182 (Conv2D)         (None, 1, 1, 2048)        1050624   \n",
            "                                                                 \n",
            " batch_normalization_195 (Ba  (None, 1, 1, 2048)       8192      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_159 (Activation)  (None, 1, 1, 2048)       0         \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 1, 1, 2048)       0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,812,426\n",
            "Trainable params: 20,766,986\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "planenet50.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "plane_history_50 = planenet50.fit(\n",
        "    ds_train,\n",
        "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
        "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
        "    epochs=EPOCH,\n",
        "    validation_data=ds_test,\n",
        "    verbose=1,\n",
        "    use_multiprocessing=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhNQr65tthOq",
        "outputId": "5fa89306-c060-4730-dbca-eae273e380a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 38s 59ms/step - loss: 2.4443 - accuracy: 0.1072 - val_loss: 2.3680 - val_accuracy: 0.0991\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 2.3604 - accuracy: 0.1129 - val_loss: 2.4417 - val_accuracy: 0.1076\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 2.3304 - accuracy: 0.1152 - val_loss: 2.5274 - val_accuracy: 0.1286\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 2.2889 - accuracy: 0.1312 - val_loss: 2.3866 - val_accuracy: 0.1345\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 2.2523 - accuracy: 0.1477 - val_loss: 2.4112 - val_accuracy: 0.1472\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 2.2032 - accuracy: 0.1688 - val_loss: 2.1982 - val_accuracy: 0.1793\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 2.1270 - accuracy: 0.1948 - val_loss: 2.1227 - val_accuracy: 0.1993\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 2.0771 - accuracy: 0.2069 - val_loss: 2.0804 - val_accuracy: 0.2234\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.9962 - accuracy: 0.2348 - val_loss: 1.9517 - val_accuracy: 0.2502\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.8968 - accuracy: 0.2712 - val_loss: 1.9800 - val_accuracy: 0.2700\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.7907 - accuracy: 0.3180 - val_loss: 1.7501 - val_accuracy: 0.3415\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.6978 - accuracy: 0.3521 - val_loss: 1.7299 - val_accuracy: 0.3600\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.6209 - accuracy: 0.3851 - val_loss: 1.5827 - val_accuracy: 0.4010\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 1.5327 - accuracy: 0.4269 - val_loss: 1.5563 - val_accuracy: 0.4213\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.4580 - accuracy: 0.4623 - val_loss: 1.6147 - val_accuracy: 0.4218\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.3941 - accuracy: 0.4903 - val_loss: 1.5249 - val_accuracy: 0.4515\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.3323 - accuracy: 0.5133 - val_loss: 1.4360 - val_accuracy: 0.4813\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 1.2660 - accuracy: 0.5423 - val_loss: 1.4041 - val_accuracy: 0.4974\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 1.2195 - accuracy: 0.5587 - val_loss: 1.5246 - val_accuracy: 0.4575\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.1519 - accuracy: 0.5862 - val_loss: 1.3889 - val_accuracy: 0.5107\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 1.1016 - accuracy: 0.6046 - val_loss: 1.3376 - val_accuracy: 0.5305\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 1.0386 - accuracy: 0.6316 - val_loss: 1.4604 - val_accuracy: 0.5007\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.9901 - accuracy: 0.6534 - val_loss: 1.4043 - val_accuracy: 0.5207\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.9270 - accuracy: 0.6745 - val_loss: 1.4118 - val_accuracy: 0.5307\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.8746 - accuracy: 0.6939 - val_loss: 1.5148 - val_accuracy: 0.5082\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.8226 - accuracy: 0.7127 - val_loss: 1.5528 - val_accuracy: 0.5140\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.7623 - accuracy: 0.7357 - val_loss: 1.5222 - val_accuracy: 0.5204\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.7181 - accuracy: 0.7539 - val_loss: 1.6189 - val_accuracy: 0.5173\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.6632 - accuracy: 0.7727 - val_loss: 1.6715 - val_accuracy: 0.5205\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.6267 - accuracy: 0.7856 - val_loss: 1.7151 - val_accuracy: 0.5179\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.5845 - accuracy: 0.8000 - val_loss: 1.7217 - val_accuracy: 0.5248\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.5518 - accuracy: 0.8121 - val_loss: 1.7566 - val_accuracy: 0.5117\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.5103 - accuracy: 0.8264 - val_loss: 1.8949 - val_accuracy: 0.5143\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.4909 - accuracy: 0.8332 - val_loss: 1.9312 - val_accuracy: 0.5144\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.4517 - accuracy: 0.8474 - val_loss: 1.8284 - val_accuracy: 0.5300\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.4326 - accuracy: 0.8545 - val_loss: 1.8761 - val_accuracy: 0.5213\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.4056 - accuracy: 0.8633 - val_loss: 2.0808 - val_accuracy: 0.5042\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.3851 - accuracy: 0.8702 - val_loss: 2.0446 - val_accuracy: 0.5167\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.3589 - accuracy: 0.8802 - val_loss: 2.0624 - val_accuracy: 0.5192\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.3366 - accuracy: 0.8857 - val_loss: 2.1347 - val_accuracy: 0.5128\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.3168 - accuracy: 0.8935 - val_loss: 2.1041 - val_accuracy: 0.5317\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.3095 - accuracy: 0.8958 - val_loss: 2.0566 - val_accuracy: 0.5253\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2904 - accuracy: 0.9021 - val_loss: 2.2167 - val_accuracy: 0.5077\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2780 - accuracy: 0.9074 - val_loss: 2.2752 - val_accuracy: 0.5269\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2659 - accuracy: 0.9087 - val_loss: 2.3023 - val_accuracy: 0.5113\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2459 - accuracy: 0.9174 - val_loss: 2.3289 - val_accuracy: 0.5195\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.2441 - accuracy: 0.9177 - val_loss: 2.4835 - val_accuracy: 0.5170\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2320 - accuracy: 0.9208 - val_loss: 2.3811 - val_accuracy: 0.5169\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2179 - accuracy: 0.9259 - val_loss: 2.3899 - val_accuracy: 0.5262\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2139 - accuracy: 0.9276 - val_loss: 2.3756 - val_accuracy: 0.5152\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.2024 - accuracy: 0.9315 - val_loss: 2.3317 - val_accuracy: 0.5293\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1930 - accuracy: 0.9355 - val_loss: 2.3632 - val_accuracy: 0.5206\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1959 - accuracy: 0.9341 - val_loss: 2.4218 - val_accuracy: 0.5187\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1872 - accuracy: 0.9368 - val_loss: 2.4338 - val_accuracy: 0.5326\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1757 - accuracy: 0.9412 - val_loss: 2.4094 - val_accuracy: 0.5299\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 32s 64ms/step - loss: 0.1741 - accuracy: 0.9405 - val_loss: 2.3868 - val_accuracy: 0.5186\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.1678 - accuracy: 0.9422 - val_loss: 2.5231 - val_accuracy: 0.5285\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.1621 - accuracy: 0.9441 - val_loss: 2.5558 - val_accuracy: 0.5169\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1569 - accuracy: 0.9460 - val_loss: 2.5319 - val_accuracy: 0.5224\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 0.1570 - accuracy: 0.9462 - val_loss: 2.6562 - val_accuracy: 0.5100\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1490 - accuracy: 0.9490 - val_loss: 2.5515 - val_accuracy: 0.5265\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1385 - accuracy: 0.9532 - val_loss: 2.5727 - val_accuracy: 0.5264\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1437 - accuracy: 0.9517 - val_loss: 2.6909 - val_accuracy: 0.5183\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1404 - accuracy: 0.9531 - val_loss: 2.5388 - val_accuracy: 0.5189\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1333 - accuracy: 0.9540 - val_loss: 2.6479 - val_accuracy: 0.5172\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1274 - accuracy: 0.9563 - val_loss: 2.6051 - val_accuracy: 0.5307\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1289 - accuracy: 0.9565 - val_loss: 2.6034 - val_accuracy: 0.5217\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1233 - accuracy: 0.9584 - val_loss: 2.5857 - val_accuracy: 0.5346\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1244 - accuracy: 0.9577 - val_loss: 2.6905 - val_accuracy: 0.5157\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1243 - accuracy: 0.9586 - val_loss: 2.7395 - val_accuracy: 0.5193\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1163 - accuracy: 0.9620 - val_loss: 2.6656 - val_accuracy: 0.5361\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1126 - accuracy: 0.9620 - val_loss: 2.5667 - val_accuracy: 0.5437\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1113 - accuracy: 0.9629 - val_loss: 2.6327 - val_accuracy: 0.5344\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 2.5567 - val_accuracy: 0.5400\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.1047 - accuracy: 0.9647 - val_loss: 2.6367 - val_accuracy: 0.5373\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1019 - accuracy: 0.9656 - val_loss: 2.5860 - val_accuracy: 0.5369\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.1036 - accuracy: 0.9641 - val_loss: 2.5975 - val_accuracy: 0.5352\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0979 - accuracy: 0.9669 - val_loss: 2.6592 - val_accuracy: 0.5348\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0978 - accuracy: 0.9673 - val_loss: 2.8375 - val_accuracy: 0.5164\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0958 - accuracy: 0.9674 - val_loss: 2.6520 - val_accuracy: 0.5308\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0988 - accuracy: 0.9670 - val_loss: 2.9378 - val_accuracy: 0.5069\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0939 - accuracy: 0.9685 - val_loss: 2.6524 - val_accuracy: 0.5323\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0938 - accuracy: 0.9691 - val_loss: 2.7736 - val_accuracy: 0.5322\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0908 - accuracy: 0.9696 - val_loss: 2.6877 - val_accuracy: 0.5356\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0902 - accuracy: 0.9695 - val_loss: 2.6581 - val_accuracy: 0.5395\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0857 - accuracy: 0.9711 - val_loss: 2.5664 - val_accuracy: 0.5407\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0872 - accuracy: 0.9710 - val_loss: 2.5876 - val_accuracy: 0.5433\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0804 - accuracy: 0.9732 - val_loss: 2.7555 - val_accuracy: 0.5361\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0807 - accuracy: 0.9729 - val_loss: 2.7015 - val_accuracy: 0.5345\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0810 - accuracy: 0.9726 - val_loss: 2.7288 - val_accuracy: 0.5273\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0845 - accuracy: 0.9719 - val_loss: 2.6871 - val_accuracy: 0.5428\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0814 - accuracy: 0.9723 - val_loss: 2.7618 - val_accuracy: 0.5313\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0808 - accuracy: 0.9728 - val_loss: 2.6307 - val_accuracy: 0.5468\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 2.7413 - val_accuracy: 0.5367\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0764 - accuracy: 0.9746 - val_loss: 2.7530 - val_accuracy: 0.5317\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0739 - accuracy: 0.9751 - val_loss: 2.7472 - val_accuracy: 0.5381\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0726 - accuracy: 0.9758 - val_loss: 2.8479 - val_accuracy: 0.5157\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0721 - accuracy: 0.9753 - val_loss: 2.7602 - val_accuracy: 0.5438\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 0.0688 - accuracy: 0.9771 - val_loss: 2.6644 - val_accuracy: 0.5485\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 0.0696 - accuracy: 0.9763 - val_loss: 2.8382 - val_accuracy: 0.5416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시각화\n",
        "ResNet34 보다 빠르게 loss가 감소하였고 정확도 역시 꽤 많이 올라갔습니다."
      ],
      "metadata": {
        "id": "suzAzzrQqPpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_50.history['loss'], 'r')\n",
        "plt.plot(plane_history_50.history['loss'], 'b')\n",
        "plt.title('Model training loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['ResNet50', 'PlaneNet_50'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UxY1zSRmt16C",
        "outputId": "e3b54226-764b-472d-a8cf-114eab9b01ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고합시다.\n",
        "단순히 인풋으로 받은 데이터를 아웃풋과 합쳐줬을 뿐인데 성능이 크게 상승했습니다.\n",
        "\n",
        "처음 논문을 보고 모델을 직접 구현해 보았는데 좀 어렵지만 나름 설명서보고 조립하는 느낌이라 생각보다 재미있었습니다."
      ],
      "metadata": {
        "id": "A4ZTBZo-qcQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cnh_bouirpAP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}